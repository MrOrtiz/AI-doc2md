# AI-doc2mdÂ ğŸš€  
*A reusable pipeline that converts mixedâ€‘format document collections into clean, chapterâ€‘level Markdownâ€”ready for any Retrievalâ€‘Augmented Generation (RAG) index.*

---

## âœ¨ What it does  
| Phase | Purpose | Key script |
|-------|---------|------------|
| **1.Â Convert** | Turn **PDF, EPUB, MOBI/AZW/LIT, DOC/DOCX, TXT** into Markdown. Parallel, dependencyâ€‘checked. | `scripts/convert_any_to_md.py` |
| **2.Â Split**   | Slice each Markdown book into perâ€‘chapter files based on heading level, in parallel. | `scripts/split_md_by_heading.py` |
| **3.Â Clean**   | You or GPT tweak the Markdown inÂ `data_clean/` (fix page headers, hyphens, etc.). | manual / GPT |
| **4.Â Ready**   | Approved chapters inÂ `data_final/` feed directly to your RAG ingestion (FAISS, Chroma, Pineconeâ€¦). | any |

Everything is driven by two standalone CLI utilitiesâ€”no hardâ€‘coded paths, fully parallel, and safe â€œdryâ€‘runâ€ modes.

---

## ğŸ“‚ Folder layout

```
AI-doc2md/
â”‚  README.md
â”‚  requirements.txt
â”‚
â”œâ”€ scripts/
â”‚   â”œâ”€ convert_any_to_md.py      # multiâ€‘format â†’ Markdown
â”‚   â””â”€ split_md_by_heading.py    # Markdown â†’ chapters
â”‚
â””â”€ corpora/
    â””â”€ <project_name>/
        â”œâ”€ data_raw/     # original docs (any supported type)
        â”œâ”€ data_md/      # autoâ€‘generated Markdown
        â”œâ”€ data_clean/   # chapter files for review
        â””â”€ data_final/   # only files you want indexed
```

Create **one subâ€‘folder per corpus**; scripts run in that folder only, so projects never collide.

---

## ğŸ› Â Installation

```bash
git clone https://github.com/<your-user>/AI-doc2md.git
cd AI-doc2md
python -m venv .venv
source .venv/bin/activate        # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### Runtime dependencies
| Tool | Used for |
|------|----------|
| **`unstructured`** (`[local-inference]` extra) | PDFÂ â†’Â Markdown (with `--ocr` support). |
| **Calibreâ€¯CLI**Â (`ebook-convert`) | EPUB / MOBI / AZW / LIT â†’Â Markdown. |
| **Pandoc + python-docx** | DOC / DOCX â†’Â Markdown fallback. |

> **Windows Calibre path**: `C:\Program Files\Calibre2\ebook-convert.exe` â€” add it to your `PATH`.

---

## âš¡ QuickÂ start (one corpus)

```bash
# create corpus skeleton
cd corpora
mkdir gov_contracting/data_raw -p

# 1â€‘â€‘ Drop your PDFs/EPUBs/etc. into data_raw/

# 2â€‘â€‘ Convert everything to Markdown (4 workers, verbose)
cd gov_contracting
python ../../scripts/convert_any_to_md.py data_raw data_md --workers 4 --verbose

# 3â€‘â€‘ Split each .md into chapters at H1 (workers=auto CPU)
python ../../scripts/split_md_by_heading.py --src data_md --dst data_clean --workers 0

# 4â€‘â€‘ Open data_clean/ in VSÂ Code, tidy, then:
mkdir data_final && cp -R data_clean/* data_final/

# 5â€‘â€‘ Point your RAG ingest:
# SOURCE_DIR = Path("AI-doc2md/corpora/gov_contracting/data_final")
```

### Command reference

#### `convert_any_to_md.py`
```
python convert_any_to_md.py <src_dir> <dst_dir> [--workers N] [--force] [--verbose]
```
* **Workers**:Â parallel processes (`0` = auto CPU count).  
* **--force**: reâ€‘process even if upâ€‘toâ€‘date.  
* Skips unchanged files by mtime comparison.

#### `split_md_by_heading.py`
```
python split_md_by_heading.py --src <dir> --dst <dir> [--level N]
                              [--workers N] [--no-split-action skip|copy]
                              [--force] [--dry-run] [--verbose]
```
* **--level**: heading depth (1Â =Â `#`, 2Â =Â `##`, â€¦).  
* **--workers 0**: auto parallel.  
* **--dry-run**: log planned writes without touching disk.  
* **--no-split-action copy**: copy whole file if no matching headings.

---

## ğŸ§© Integrating with your RAG

```python
from pathlib import Path
SOURCE_DIR = Path(r"C:/AI-doc2md/corpora/gov_contracting/data_final")
```

Point your `ingest.py` at `SOURCE_DIR`â€”done.

---

## ğŸš€  Typical daily workflow
1. **Add** new docs â†’ `data_raw/`
2. `convert_any_to_md.py â€¦`
3. `split_md_by_heading.py â€¦`
4. **Edit** chapters in `data_clean/`
5. Copy approved files â†’ `data_final/`
6. **Reâ€‘index** with FAISS/Chroma etc.

---

## ğŸ¤– FAQ
| Q | A |
|---|---|
| Scanned PDFs? | Add `--ocr` flag in `convert_any_to_md.py` (requires Tesseract). |
| Need only certain formats? | Use `--extensions .pdf,.epub` (see script help). |
| Reâ€‘run nightly? | Schedule Taskâ€‘Scheduler / cron calling both scripts. |
| Multiâ€‘gig corpora? | Raise `--workers`, ensure SSD; scripts stream files so RAM usage is low. |

---

## ğŸ“œ License
MIT â€“ use it for anything. Contributions welcome!

Enjoy painless, repeatable document ingestion for *any* RAG project ğŸª„
